{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1687787597342
        }
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import psycopg2\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import re\n",
        "import requests, uuid, json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1687787599042
        }
      },
      "outputs": [],
      "source": [
        "openai.api_type = \"azure\"\n",
        "openai.api_base = \"https://fusion-gpt-training.openai.azure.com/\"\n",
        "openai.api_version = \"2023-07-01-preview\"\n",
        "openai.api_key = \"a83037e20d3d4d7982b0c52080e730fb\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1687787600702
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "host = \"pureelawvec.postgres.database.azure.com\"\n",
        "dbname = \"postgres\"\n",
        "user = \"pgadmin\"\n",
        "password = \"Puree1234\"\n",
        "sslmode = \"require\"\n",
        "# Construct connection string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1687787604150
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connection established\n"
          ]
        }
      ],
      "source": [
        "conn_string = \"host={0} user={1} dbname={2} password={3} sslmode={4}\".format(host, user, dbname, password, sslmode)\n",
        "conn = psycopg2.connect(conn_string) \n",
        "print(\"Connection established\")\n",
        "cursor = conn.cursor()\n",
        "# Fetch all rows from table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "import openai  # Make sure to import the OpenAI library\n",
        "\n",
        "class Chatbot():\n",
        "    def __init__(self):\n",
        "        self.memory = [{\"role\": \"system\", \"content\": \"\"}, {\"role\": \"user\", \"content\": \"\"}]\n",
        "        self.Lawyer_prompt = \"LawBot, a GPT-based AI assistant designed specifically for answering legal questions and explaining complex legal terms.\\\n",
        "        Analysis the Question sector and provide a comprehensive and briefly answer in Answer section.The answer must address all aspects\\\n",
        "        of the Question and support your argument with appropriate legal references in Context section. Only answered by thai language only \"\n",
        "    \n",
        "    def thai2eng(self ,input):\n",
        "        key = \"041e6b79b96146eabafaf524d78911be\"\n",
        "        endpoint = \"https://api.cognitive.microsofttranslator.com\"\n",
        "        location = \"southeastasia\"\n",
        "        path = '/translate'\n",
        "        constructed_url = endpoint + path\n",
        "        params = {\n",
        "            'api-version': '3.0',\n",
        "            'from': 'th',\n",
        "            'to': ['en']\n",
        "        }\n",
        "        headers = {\n",
        "            'Ocp-Apim-Subscription-Key': key,\n",
        "            'Ocp-Apim-Subscription-Region': location,\n",
        "            'Content-type': 'application/json',\n",
        "            'X-ClientTraceId': str(uuid.uuid4())\n",
        "        }\n",
        "        body = [{\n",
        "            'text': input\n",
        "        }]\n",
        "        request = requests.post(constructed_url, params=params, headers=headers, json=body)\n",
        "        response = request.json()\n",
        "        return response[0][\"translations\"][0]['text']\n",
        "\n",
        "    def text2vec(self, input):\n",
        "        embed_list = []\n",
        "        model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "        embeddings = model.encode(input)\n",
        "        embed_list.append(embeddings.tolist())\n",
        "        return embed_list[0]\n",
        "\n",
        "    def search_vectordb(self, question):\n",
        "        search_text = []\n",
        "        try:\n",
        "            cursor.execute(f\"\"\"SELECT text_thai, cosine_distance('{self.text2vec(question)}', embedding) as cosign\n",
        "            FROM Criminal_Law\n",
        "            ORDER BY cosine_distance('{self.text2vec(question)}', embedding) ASC LIMIT 7\n",
        "            \"\"\")\n",
        "            query = cursor.fetchall()\n",
        "            text_eng_results = [row[0] for row in query] \n",
        "            return text_eng_results\n",
        "        except Exception as e:  \n",
        "                print(f\"Error: {e}\")\n",
        "                conn.rollback()\n",
        "        return \"Not found any related.\"\n",
        "\n",
        "    def gpt3_sum(self, user_input, engine='gpt-35-turbo', temp=0.5, top_p=0.95, tokens=2000, freq_pen=0.0, pres_pen=0.2):\n",
        "        retry, max_retry = 0, 10\n",
        "        while retry < max_retry:\n",
        "            try:\n",
        "                setting = [{\"role\": \"system\", \"content\": \"Summary the user input as a bullet, use only Thai language\"}, \n",
        "                        {\"role\": \"user\", \"content\": f\"{user_input}\"}]\n",
        "                response = openai.ChatCompletion.create(engine=engine, temperature=temp, max_tokens=tokens,\n",
        "                                                        top_p=top_p, frequency_penalty=freq_pen, presence_penalty=pres_pen,\n",
        "                                                        messages=setting)\n",
        "                return response['choices'][0]['message']['content']\n",
        "            except openai.error.OpenAIError as e:\n",
        "                print(f\"Error: {e}\")\n",
        "                retry += 1\n",
        "                if retry < max_retry:\n",
        "                    print(f\"Due to content filtering, retrying. (attempt {retry}/{max_retry})...\")\n",
        "                    time.sleep(3)  # Add a delay before retrying\n",
        "                else:\n",
        "                    print(\"Max retries reached. Exiting. Please change the question\")\n",
        "                    break\n",
        "        return response['choices'][0]['message']['content']\n",
        "    def chat(self, user_input, engine='gpt-4-32k', temp=0.5, top_p=0.95, tokens=4000, freq_pen=0.0, pres_pen=0.2):\n",
        "        retry, max_retry = 0, 10\n",
        "        while retry < max_retry:\n",
        "            try:\n",
        "                # user_input = input(\"User:\")\n",
        "                # if user_input == \"stop\":\n",
        "                #     retry += max_retry\n",
        "                #     break\n",
        "                self.clear_memory()\n",
        "                self.update_memory('user', user_input)\n",
        "                lawyer_prompt_content = self.Lawyer_prompt + ''.join(self.search_vectordb(self.thai2eng(self.gpt3_sum(user_input))))\n",
        "                self.update_memory('system', lawyer_prompt_content)\n",
        "                response = openai.ChatCompletion.create(engine=engine, temperature=temp, max_tokens=tokens,\n",
        "                                                        top_p=top_p, frequency_penalty=freq_pen, presence_penalty=pres_pen,\n",
        "                                                        messages=self.memory)\n",
        "                # self.update_memory('system', \"This is memory section that keep old conversation <memory>{mem}</memory>\"\n",
        "                #     .format(mem = response['choices'][0]['message']['content']))\n",
        "                # print(\"LawChatBot:\", response['choices'][0]['message']['content'])\n",
        "                return response['choices'][0]['message']['content']\n",
        "            except openai.error.OpenAIError as e:\n",
        "                print(f\"Error: {e}\")\n",
        "                retry += 1\n",
        "                if retry < max_retry:\n",
        "                    print(f\"Due to content filtering, retrying. (attempt {retry}/{max_retry})...\")\n",
        "                    time.sleep(3)  # Add a delay before retrying\n",
        "                else:\n",
        "                    print(\"Max retries reached. Exiting. Please change the question\")\n",
        "                    break\n",
        "                \n",
        "    def update_memory(self, role, content):\n",
        "        self.memory.append({\"role\": role, \"content\": content})\n",
        "        \n",
        "    def clear_memory(self):\n",
        "        self.memory = [{\"role\": \"system\", \"content\": \"\"}, {\"role\": \"user\", \"content\": \"\"}]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "bot = Chatbot() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Chatbot.clear_memory() takes 1 positional argument but 2 were given",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Puree\\Desktop\\work\\Project_law\\TCL_VectorDB\\Postgresql-vector-law-Copy.ipynb Cell 7\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Puree/Desktop/work/Project_law/TCL_VectorDB/Postgresql-vector-law-Copy.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#ขโมยของผิดไหม\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Puree/Desktop/work/Project_law/TCL_VectorDB/Postgresql-vector-law-Copy.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#ฆ่าคนมีความผิดไหม\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Puree/Desktop/work/Project_law/TCL_VectorDB/Postgresql-vector-law-Copy.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m bot\u001b[39m.\u001b[39;49mchat(\u001b[39m\"\u001b[39;49m\u001b[39mขโมยของมีความผิดไหม\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
            "\u001b[1;32mc:\\Users\\Puree\\Desktop\\work\\Project_law\\TCL_VectorDB\\Postgresql-vector-law-Copy.ipynb Cell 7\u001b[0m line \u001b[0;36m8\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Puree/Desktop/work/Project_law/TCL_VectorDB/Postgresql-vector-law-Copy.ipynb#W6sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m \u001b[39mwhile\u001b[39;00m retry \u001b[39m<\u001b[39m max_retry:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Puree/Desktop/work/Project_law/TCL_VectorDB/Postgresql-vector-law-Copy.ipynb#W6sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Puree/Desktop/work/Project_law/TCL_VectorDB/Postgresql-vector-law-Copy.ipynb#W6sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m         \u001b[39m# user_input = input(\"User:\")\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Puree/Desktop/work/Project_law/TCL_VectorDB/Postgresql-vector-law-Copy.ipynb#W6sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m         \u001b[39m# if user_input == \"stop\":\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Puree/Desktop/work/Project_law/TCL_VectorDB/Postgresql-vector-law-Copy.ipynb#W6sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m         \u001b[39m#     retry += max_retry\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Puree/Desktop/work/Project_law/TCL_VectorDB/Postgresql-vector-law-Copy.ipynb#W6sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m         \u001b[39m#     break\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Puree/Desktop/work/Project_law/TCL_VectorDB/Postgresql-vector-law-Copy.ipynb#W6sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclear_memory(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Puree/Desktop/work/Project_law/TCL_VectorDB/Postgresql-vector-law-Copy.ipynb#W6sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_memory(\u001b[39m'\u001b[39m\u001b[39muser\u001b[39m\u001b[39m'\u001b[39m, user_input)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Puree/Desktop/work/Project_law/TCL_VectorDB/Postgresql-vector-law-Copy.ipynb#W6sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m         lawyer_prompt_content \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLawyer_prompt \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msearch_vectordb(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mthai2eng(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgpt3_sum(user_input))))\n",
            "\u001b[1;31mTypeError\u001b[0m: Chatbot.clear_memory() takes 1 positional argument but 2 were given"
          ]
        }
      ],
      "source": [
        "#ขโมยของผิดไหม\n",
        "#ฆ่าคนมีความผิดไหม\n",
        "bot.chat(\"ขโมยของมีความผิดไหม\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(r\"C:\\Users\\Puree\\Desktop\\work\\Project_law\\validation.csv\", encoding = \"utf-8\")\n",
        "chat_ans = []\n",
        "for data in range(3):\n",
        "    x = bot.chat(df.Question.iloc[data])\n",
        "    chat_ans.append(x)\n",
        "answer = pd.DataFrame(chat_ans, columns=[\"Answer\"])\n",
        "answer.to_csv(\"./answer_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "gather": {
          "logged": 1687787241694
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "conn.commit()\n",
        "cursor.close()\n",
        "conn.close()"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
