{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os, re\n",
    "import requests, uuid, json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://fusion-gpt-training.openai.azure.com/\"\n",
    "openai.api_version = \"2023-07-01-preview\"\n",
    "openai.api_key = \"a83037e20d3d4d7982b0c52080e730fb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = \"pureelawvec.postgres.database.azure.com\"\n",
    "dbname = \"postgres\"\n",
    "user = \"pgadmin\"\n",
    "password = \"Puree1234\"\n",
    "sslmode = \"require\"\n",
    "# Construct connection string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_string = \"host={0} user={1} dbname={2} password={3} sslmode={4}\".format(host, user, dbname, password, sslmode)\n",
    "conn = psycopg2.connect(conn_string) \n",
    "print(\"Connection established\")\n",
    "cursor = conn.cursor()\n",
    "# Fetch all rows from table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"law.csv\")\n",
    "df['Content'] = df['Content'].str.replace(\"\\n\", \" \")\n",
    "# Extract sections using regular expressions\n",
    "pattern = r'Section \\d+\\..*?(?=Section \\d+\\.|$)'\n",
    "df['Section'] = df['Content'].apply(lambda x: re.findall(pattern, x, re.DOTALL))\n",
    "# Explode the list of sections into separate rows\n",
    "df = df.explode('Section')\n",
    "df_text = df.drop('Content', axis= 1)\n",
    "# # Reset index\n",
    "df_text.reset_index(drop=True, inplace=True)\n",
    "df = df_text.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.squeeze(df.Section.values)\n",
    "sentence_list = [x for x in x]\n",
    "sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated = []\n",
    "for item in sentence_list:\n",
    "    translated.append(eng2thai(item))\n",
    "translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "embed_list = []\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(sentence_list)\n",
    "embed_list.append(embeddings.tolist())\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # cursor.execute(\"CREATE EXTENSION IF NOT EXISTS pg_trgm;\")\n",
    "    cursor.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n",
    "    cursor.execute(\"\"\" \n",
    "    CREATE TABLE Criminal_Law(\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        embedding vector,\n",
    "        text_eng TEXT,\n",
    "        text_thai TEXT\n",
    "    );\"\"\")\n",
    "    for i in range(len(sentence_list)):  \n",
    "        cursor.execute(\"INSERT INTO Criminal_Law(id, embedding, text_eng, text_thai) VALUES (%s, %s, %s, %s);\",   \n",
    "                    (i, embed_list[0][i], sentence_list[i], translated[i]))\n",
    "        print(sentence_list[i]) \n",
    "        print(embed_list[0][i])\n",
    "        conn.commit()  \n",
    "except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2vec(input):\n",
    "    embed_list = []\n",
    "    model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "    embeddings = model.encode(input)\n",
    "    embed_list.append(embeddings.tolist())\n",
    "    return embed_list[0]\n",
    "\n",
    "def search_vectordb(question):# Query vector\n",
    "    search_text = []\n",
    "    try:\n",
    "         cursor.execute(f\"\"\"SELECT text_thai, cosine_distance('{text2vec(question)}', embedding) as cosign\n",
    "         FROM Criminal_Law\n",
    "         ORDER BY cosine_distance('{text2vec(question)}', embedding) ASC LIMIT 7\n",
    "         \"\"\")\n",
    "         query = cursor.fetchall()\n",
    "         text_eng_results = [row[0] for row in query] \n",
    "         return text_eng_results\n",
    "    except Exception as e:  \n",
    "            print(f\"Error: {e}\")\n",
    "            conn.rollback()\n",
    "    return \"null\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
